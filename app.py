# app.py - VERS√ÉO COM LLM PARA AN√ÅLISE INTELIGENTE
import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
import plotly.graph_objects as go
from io import StringIO, BytesIO
import base64
from datetime import datetime
import warnings
import requests
import json
warnings.filterwarnings('ignore')

# Configura√ß√£o da p√°gina
st.set_page_config(
    page_title="Agente de IA - An√°lise de Dados CSV",
    page_icon="üìä",
    layout="wide"
)

# Sistema de mem√≥ria para conversa√ß√£o
class ConversationMemory:
    def __init__(self):
        if 'conversation_history' not in st.session_state:
            st.session_state.conversation_history = []
        if 'analysis_insights' not in st.session_state:
            st.session_state.analysis_insights = []
    
    def add_message(self, role, content):
        timestamp = datetime.now().strftime("%H:%M:%S")
        st.session_state.conversation_history.append({
            'timestamp': timestamp,
            'role': role,
            'content': content
        })
    
    def add_insight(self, insight):
        st.session_state.analysis_insights.append(insight)
    
    def get_conversation_history(self):
        return st.session_state.conversation_history
    
    def get_insights(self):
        return st.session_state.analysis_insights

# Classe para integra√ß√£o com LLM
class LLMAnalyzer:
    def __init__(self):
        # A chave ser√° carregada dos secrets do Streamlit
        self.api_key = st.secrets.get("OPENAI_API_KEY", "")
        self.base_url = "https://api.openai.com/v1/chat/completions"
    
    def analyze_with_llm(self, question, df_info):
        """Usa LLM para interpretar a pergunta e sugerir an√°lises"""
        
        # Se n√£o h√° API key, usa respostas program√°ticas
        if not self.api_key:
            return self._get_fallback_response(question, df_info)
        
        prompt = f"""
        Voc√™ √© um especialista em an√°lise de dados. Um usu√°rio fez a seguinte pergunta sobre um dataset:

        PERGUNTA: "{question}"
        
        INFORMA√á√ïES DO DATASET:
        - Colunas dispon√≠veis: {df_info['columns']}
        - Tipos de dados: {df_info['dtypes']}
        - Total de linhas: {df_info['rows']}
        
        Sua tarefa √©:
        1. Interpretar o que o usu√°rio quer saber
        2. Sugerir as melhores an√°lises estat√≠sticas
        3. Recomendar visualiza√ß√µes apropriadas
        4. Dar insights sobre o que procurar nos dados

        Responda em portugu√™s de forma clara e direta, focando em an√°lises pr√°ticas que podem ser implementadas.
        """
        
        try:
            headers = {
                "Authorization": f"Bearer {self.api_key}",
                "Content-Type": "application/json"
            }
            
            data = {
                "model": "gpt-3.5-turbo",
                "messages": [{"role": "user", "content": prompt}],
                "max_tokens": 500,
                "temperature": 0.3
            }
            
            response = requests.post(self.base_url, headers=headers, json=data, timeout=30)
            response.raise_for_status()
            
            result = response.json()
            return result['choices'][0]['message']['content']
            
        except Exception as e:
            st.error(f"Erro na consulta √† LLM: {str(e)}")
            return self._get_fallback_response(question, df_info)
    
    def _get_fallback_response(self, question, df_info):
        """Resposta fallback quando n√£o h√° LLM dispon√≠vel"""
        question_lower = question.lower()
        
        if any(word in question_lower for word in ['tipo', 'dados', 'coluna']):
            return f"üîç **An√°lise de Tipos de Dados**: O dataset possui {len(df_info['columns'])} colunas. Recomendo verificar a distribui√ß√£o entre vari√°veis num√©ricas e categ√≥ricas, e analisar a completude dos dados."
        
        elif any(word in question_lower for word in ['estat√≠stica', 'm√©dia', 'mediana']):
            return "üìä **An√°lise Estat√≠stica**: Sugiro calcular medidas de tend√™ncia central (m√©dia, mediana), dispers√£o (desvio padr√£o, vari√¢ncia) e analisar a distribui√ß√£o dos dados atrav√©s de histogramas e boxplots."
        
        elif any(word in question_lower for word in ['histograma', 'distribui√ß√£o']):
            col_suggestion = df_info['columns'][0] if df_info['columns'] else 'V1'
            return f"üìà **An√°lise de Distribui√ß√£o**: Recomendo histogramas para entender a distribui√ß√£o das vari√°veis. Comece pela coluna '{col_suggestion}'. Observe assimetria, curtose e poss√≠veis bimodalidades."
        
        elif any(word in question_lower for word in ['correla√ß√£o', 'rela√ß√£o']):
            return "üîÑ **An√°lise de Correla√ß√£o**: Sugiro matriz de correla√ß√£o para identificar rela√ß√µes lineares entre vari√°veis. Valores pr√≥ximos de ¬±1 indicam forte correla√ß√£o. Gr√°ficos de dispers√£o podem revelar padr√µes n√£o lineares."
        
        elif any(word in question_lower for word in ['outlier', 'anomalia']):
            return "‚ö° **Detec√ß√£o de Anomalias**: Use m√©todo IQR (Intervalo Interquartil) para identificar outliers. Valores outside de Q1 - 1.5IQR ou Q3 + 1.5IQR s√£o considerados at√≠picos. Analise o impacto desses valores nas conclus√µes."
        
        else:
            return f"ü§î **An√°lise Explorat√≥ria**: Para '{question}', recomendo: 1) Estat√≠sticas descritivas b√°sicas 2) An√°lise de distribui√ß√£o 3) Verifica√ß√£o de valores missing 4) Identifica√ß√£o de padr√µes iniciais nos dados."

# Fun√ß√µes de an√°lise de dados
class DataAnalyzer:
    def __init__(self, df):
        self.df = df
        self.numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
        self.categorical_cols = df.select_dtypes(include=['object']).columns.tolist()
    
    def get_data_types(self):
        return {
            'numeric': self.numeric_cols,
            'categorical': self.categorical_cols,
            'total_columns': len(self.df.columns),
            'total_rows': len(self.df)
        }
    
    def generate_summary_statistics(self):
        return self.df.describe()
    
    def detect_outliers(self, column):
        if column in self.numeric_cols:
            Q1 = self.df[column].quantile(0.25)
            Q3 = self.df[column].quantile(0.75)
            IQR = Q3 - Q1
            lower_bound = Q1 - 1.5 * IQR
            upper_bound = Q3 + 1.5 * IQR
            outliers = self.df[(self.df[column] < lower_bound) | (self.df[column] > upper_bound)]
            return len(outliers)
        return 0
    
    def correlation_analysis(self):
        numeric_df = self.df[self.numeric_cols]
        if len(numeric_df.columns) > 1:
            return numeric_df.corr()
        return None
    
    def create_histogram(self, column):
        if column in self.df.columns:
            fig = px.histogram(self.df, x=column, title=f'Distribui√ß√£o de {column}')
            return fig
        return None
    
    def create_scatter_plot(self, x_col, y_col):
        if x_col in self.df.columns and y_col in self.df.columns:
            fig = px.scatter(self.df, x=x_col, y=y_col, title=f'{x_col} vs {y_col}')
            return fig
        return None
    
    def create_box_plot(self, column):
        if column in self.df.columns:
            fig = px.box(self.df, y=column, title=f'Box Plot - {column}')
            return fig
        return None

# Agente principal
class DataAnalysisAgent:
    def __init__(self):
        self.memory = ConversationMemory()
        self.analyzer = None
        self.llm_analyzer = LLMAnalyzer()  # Integra√ß√£o com LLM
    
    def load_data(self, uploaded_file):
        try:
            if uploaded_file.name.endswith('.csv'):
                df = pd.read_csv(uploaded_file)
            else:
                return None, "Formato de arquivo n√£o suportado. Por favor, envie um arquivo CSV."
            
            self.analyzer = DataAnalyzer(df)
            self.memory.add_insight(f"Dados carregados: {len(df)} linhas, {len(df.columns)} colunas")
            return df, "Dados carregados com sucesso!"
        except Exception as e:
            return None, f"Erro ao carregar dados: {str(e)}"
    
    def load_demo_data(self, df):
        self.analyzer = DataAnalyzer(df)
        self.memory.add_insight(f"Dados de exemplo carregados: {len(df)} linhas, {len(df.columns)} colunas")
        return df, "Dataset de exemplo carregado com sucesso!"
    
    def get_llm_insights(self, question, df):
        """Obt√©m insights da LLM sobre a pergunta"""
        df_info = {
            'columns': df.columns.tolist(),
            'dtypes': {col: str(df[col].dtype) for col in df.columns},
            'rows': len(df)
        }
        
        llm_response = self.llm_analyzer.analyze_with_llm(question, df_info)
        return llm_response
    
    def analyze_question(self, question, df):
        question_lower = question.lower()
        insights = []
        
        # An√°lise de tipos de dados
        if any(word in question_lower for word in ['tipo', 'dados', 'coluna', 'vari√°vel']):
            data_types = self.analyzer.get_data_types()
            insights.append(f"**Tipos de Dados:**")
            insights.append(f"- Colunas num√©ricas: {len(data_types['numeric'])}")
            insights.append(f"- Colunas categ√≥ricas: {len(data_types['categorical'])}")
            insights.append(f"- Total: {data_types['total_columns']} colunas, {data_types['total_rows']} linhas")
        
        # Estat√≠sticas descritivas
        if any(word in question_lower for word in ['estat√≠stica', 'm√©dia', 'mediana', 'desvio', 'vari√¢ncia']):
            stats = self.analyzer.generate_summary_statistics()
            insights.append("**Estat√≠sticas Descritivas:**")
            for col in stats.columns[:3]:
                insights.append(f"- {col}: m√©dia={stats[col]['mean']:.2f}, mediana={stats[col]['50%']:.2f}, desvio={stats[col]['std']:.2f}")
        
        # Detec√ß√£o de outliers
        if any(word in question_lower for word in ['outlier', 'anomalia', 'at√≠pico']):
            insights.append("**Detec√ß√£o de Outliers:**")
            outlier_found = False
            for col in self.analyzer.numeric_cols[:5]:
                outlier_count = self.analyzer.detect_outliers(col)
                if outlier_count > 0:
                    insights.append(f"- {col}: {outlier_count} outliers detectados")
                    outlier_found = True
            if not outlier_found:
                insights.append("- Nenhum outlier significativo detectado nas principais colunas")
        
        # Correla√ß√£o
        if any(word in question_lower for word in ['correla√ß√£o', 'rela√ß√£o', 'associa√ß√£o']):
            corr_matrix = self.analyzer.correlation_analysis()
            if corr_matrix is not None:
                high_corr = []
                for i in range(len(corr_matrix.columns)):
                    for j in range(i+1, len(corr_matrix.columns)):
                        corr_value = corr_matrix.iloc[i, j]
                        if abs(corr_value) > 0.7:
                            high_corr.append(f"{corr_matrix.columns[i]} - {corr_matrix.columns[j]}: {corr_value:.2f}")
                
                if high_corr:
                    insights.append("**Correla√ß√µes Fortes (>0.7):**")
                    insights.extend([f"- {corr}" for corr in high_corr[:3]])
                else:
                    insights.append("**Correla√ß√µes:** Nenhuma correla√ß√£o forte (>0.7) encontrada")
        
        # Distribui√ß√£o
        if any(word in question_lower for word in ['distribui√ß√£o', 'histograma', 'frequ√™ncia']):
            insights.append("**An√°lise de Distribui√ß√£o:**")
            available_cols = self.analyzer.numeric_cols[:3]
            for col in available_cols:
                insights.append(f"- {col}: dispon√≠vel para an√°lise de distribui√ß√£o")
        
        # Se n√£o encontrou padr√µes espec√≠ficos, dar uma resposta geral
        if not insights:
            insights.append("**An√°lise Geral:**")
            insights.append(f"- Dataset com {len(df)} linhas e {len(df.columns)} colunas")
            insights.append(f"- Colunas num√©ricas: {len(self.analyzer.numeric_cols)}")
            insights.append("- Use perguntas espec√≠ficas para an√°lises detalhadas")
        
        return insights
    
    def generate_visualization(self, question, df):
        question_lower = question.lower()
        
        # Histograma
        if 'histograma' in question_lower:
            for col in self.analyzer.numeric_cols:
                if col.lower() in question_lower:
                    return self.analyzer.create_histogram(col)
            # Se n√£o especificou coluna, usar a primeira num√©rica
            if self.analyzer.numeric_cols:
                return self.analyzer.create_histogram(self.analyzer.numeric_cols[0])
        
        # Dispers√£o
        if 'dispers√£o' in question_lower or 'scatter' in question_lower:
            numeric_cols = self.analyzer.numeric_cols
            if len(numeric_cols) >= 2:
                return self.analyzer.create_scatter_plot(numeric_cols[0], numeric_cols[1])
        
        # Box plot
        if 'box' in question_lower or 'boxplot' in question_lower:
            for col in self.analyzer.numeric_cols:
                if col.lower() in question_lower:
                    return self.analyzer.create_box_plot(col)
            if self.analyzer.numeric_cols:
                return self.analyzer.create_box_plot(self.analyzer.numeric_cols[0])
        
        return None

def main():
    st.title("üîç Agente de IA - An√°lise Inteligente de Dados CSV")
    st.markdown("""
    Este agente usa **Intelig√™ncia Artificial** para analisar qualquer arquivo CSV, gerar visualiza√ß√µes e insights inteligentes.
    Fa√ßa perguntas em linguagem natural e obtenve an√°lises avan√ßadas!
    """)
    
    # Informa√ß√µes sobre a LLM
    with st.expander("‚ÑπÔ∏è Sobre a Intelig√™ncia Artificial"):
        st.info("""
        **Este agente utiliza:**
        - ü§ñ **LLM (Large Language Model)** para interpretar suas perguntas e sugerir an√°lises
        - üìä **An√°lise estat√≠stica program√°tica** para executar os c√°lculos
        - üìà **Visualiza√ß√µes interativas** para explorar os dados
        
        **Privacidade:** Suos dados N√ÉO s√£o enviados para a API - apenas metadados sobre as colunas.
        """)
    
    # Inicializa√ß√£o do agente
    if 'agent' not in st.session_state:
        st.session_state.agent = DataAnalysisAgent()
    
    agent = st.session_state.agent
    
    # Inicializar selected_question se n√£o existir
    if 'selected_question' not in st.session_state:
        st.session_state.selected_question = ""
    
    # Upload de arquivo
    uploaded_file = st.file_uploader("üì§ Carregue seu arquivo CSV", type=['csv'])
    
    # Bot√£o para dados de exemplo
    if not uploaded_file and st.button("üöÄ Carregar Dataset de Exemplo (Fraudes)"):
        # Criar dados de exemplo
        np.random.seed(42)
        n_samples = 1000
        
        example_data = {
            'Time': np.random.exponential(1000, n_samples),
            'V1': np.random.normal(0, 1, n_samples),
            'V2': np.random.normal(0, 1, n_samples),
            'V3': np.random.normal(0, 1, n_samples),
            'Amount': np.random.exponential(100, n_samples),
            'Class': np.random.choice([0, 1], n_samples, p=[0.99, 0.01])
        }
        
        df_example = pd.DataFrame(example_data)
        agent.load_demo_data(df_example)
        st.session_state.demo_mode = True
        st.session_state.current_df = df_example
        st.success("‚úÖ Dataset de exemplo carregado com sucesso!")
        st.rerun()
    
    # Processar arquivo upload ou demo
    current_df = None
    if uploaded_file is not None:
        current_df, message = agent.load_data(uploaded_file)
        if current_df is not None:
            st.success(message)
            st.session_state.demo_mode = False
            st.session_state.current_df = current_df
    elif st.session_state.get('demo_mode', False):
        current_df = st.session_state.get('current_df', None)
    
    if current_df is not None:
        # Sidebar com informa√ß√µes do dataset
        with st.sidebar:
            st.header("üìä Informa√ß√µes do Dataset")
            st.write(f"**Shape:** {current_df.shape[0]} linhas √ó {current_df.shape[1]} colunas")
            
            st.subheader("Pr√©-visualiza√ß√£o dos Dados")
            st.dataframe(current_df.head(10))
            
            st.subheader("Colunas")
            for col in current_df.columns:
                st.write(f"- {col} ({current_df[col].dtype})")
        
        # √Årea de perguntas e respostas
        col1, col2 = st.columns([2, 1])
        
        with col1:
            st.subheader("üí¨ Fa√ßa sua pergunta")
            
            # Usar approach diferente - criar um form
            with st.form(key='question_form'):
                question = st.text_input(
                    "Exemplos: 'Quais s√£o os tipos de dados?', 'Mostre um histograma', 'Existem outliers?'",
                    value=st.session_state.selected_question
                )
                
                submit_button = st.form_submit_button("üîç Analisar com IA")
                
                if submit_button and question:
                    with st.spinner("ü§ñ Consultando IA e analisando dados..."):
                        # NOVO: Obter insights da LLM
                        llm_insights = agent.get_llm_insights(question, current_df)
                        
                        # An√°lise program√°tica tradicional
                        insights = agent.analyze_question(question, current_df)
                        visualization = agent.generate_visualization(question, current_df)
                        
                        # Adicionar √† mem√≥ria
                        agent.memory.add_message("user", question)
                        
                        # NOVO: Exibir insights da LLM
                        st.markdown("## ü§ñ Insights da Intelig√™ncia Artificial")
                        st.info(llm_insights)
                        
                        # Exibir an√°lise program√°tica
                        if insights:
                            response = "## üìà An√°lise Estat√≠stica Executada\n\n" + "\n".join(insights)
                            agent.memory.add_message("assistant", response)
                            st.markdown(response)
                        
                        # Exibir visualiza√ß√£o
                        if visualization:
                            st.plotly_chart(visualization, use_container_width=True)
                            agent.memory.add_insight(f"Gr√°fico gerado para: {question}")
                        elif any(word in question.lower() for word in ['histograma', 'gr√°fico', 'visualiza√ß√£o']):
                            st.warning("‚ö†Ô∏è N√£o foi poss√≠vel gerar o gr√°fico. Tente especificar uma coluna num√©rica.")
            
            # Limpar selected_question ap√≥s usar
            if st.session_state.selected_question:
                st.session_state.selected_question = ""
        
        with col2:
            st.subheader("üí° Perguntas Sugeridas")
            suggested_questions = [
                "Quais s√£o os tipos de dados?",
                "Mostre estat√≠sticas descritivas",
                "Existem outliers nos dados?",
                "Mostre um histograma",
                "Quais as correla√ß√µes entre vari√°veis?",
                "Qual a distribui√ß√£o dos dados?"
            ]
            
            for i, q in enumerate(suggested_questions):
                if st.button(q, key=f"btn_{i}"):
                    st.session_state.selected_question = q
                    st.rerun()
        
        # Hist√≥rico da conversa
        st.subheader("üìù Hist√≥rico da An√°lise")
        conversation_history = agent.memory.get_conversation_history()
        
        if conversation_history:
            for msg in conversation_history[-10:]:
                with st.chat_message(msg['role']):
                    st.markdown(msg['content'])
        else:
            st.info("üí° Fa√ßa sua primeira pergunta para come√ßar a an√°lise!")
        
        # Insights gerais
        st.subheader("üéØ Conclus√µes do Agente")
        insights = agent.memory.get_insights()
        if insights:
            for insight in insights[-5:]:
                st.info(insight)
        else:
            st.info("üîç As conclus√µes aparecer√£o aqui ap√≥s as an√°lises")
    
    else:
        st.info("üëÜ Por favor, carregue um arquivo CSV ou use o dataset de exemplo para come√ßar a an√°lise")

if __name__ == "__main__":
    main()